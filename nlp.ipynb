{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39cd6865-d589-4a4b-bd5f-d39edfb2b552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recommendation is:Rec2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MedianElimination:\n",
    "    def _init_(self, arms, delta, epsilon):\n",
    "        self.arms = arms\n",
    "        self.delta = delta\n",
    "        self.epsilon = epsilon\n",
    "        self.n_arms = len(arms)\n",
    "\n",
    "    def simulate_feedback(self, arm):\n",
    "        true_rewards = {arm: np.random.uniform(0.5, 1.0) for arm in self.arms}\n",
    "        return np.random.binomial(1, true_rewards[arm])\n",
    "\n",
    "    def run(self):\n",
    "        remaining_arms = self.arms.copy()\n",
    "        delta = self.delta\n",
    "        epsilon = self.epsilon\n",
    "        \n",
    "        while len(remaining_arms) > 1:\n",
    "            n_rounds = int(np.ceil(4 / epsilon**2 * np.log(3 / delta)))\n",
    "            rewards = {arm: [] for arm in remaining_arms}\n",
    "            for _ in range(n_rounds):\n",
    "                for arm in remaining_arms:\n",
    "                    reward = self.simulate_feedback(arm)\n",
    "                    rewards[arm].append(reward)\n",
    "            sample_means = {arm: np.mean(rewards[arm]) for arm in remaining_arms}\n",
    "            median = np.median(list(sample_means.values()))\n",
    "            remaining_arms = [arm for arm in remaining_arms if sample_means[arm] >= median]\n",
    "            epsilon /= 2\n",
    "            delta /= 2\n",
    "        \n",
    "        return remaining_arms[0]\n",
    "\n",
    "if __name__ == \"_main_\":\n",
    "    np.random.seed(42)  \n",
    "    recommendations = [\"Rec1\", \"Rec2\", \"Rec3\", \"Rec4\"]\n",
    "    delta = 0.1\n",
    "    epsilon = 0.1\n",
    "    algorithm = MedianElimination(recommendations, delta, epsilon)\n",
    "    best_recommendation = algorithm.run()\n",
    "    print(f\"The best recommendation is: {best_recommendation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091513c2-f972-4707-a088-949f8cf798b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m uesr_vector\u001b[38;5;241m=\u001b[39mtfidf_matrix[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "uesr_vector=tfidf_matrix[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b155588-1313-43e2-8e7a-7abfd5fdc517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Natural language processing helps AI understand human text. - Similarity: 0.3399\n",
      "Response: AI is transforming industries through automation. - Similarity: 0.0749\n",
      "Response: Machine learning is a subset of AI that helps in predictions. - Similarity: 0.0580\n",
      "Response: Deep learning involves neural networks for complex tasks. - Similarity: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "responses = [\n",
    "    \"AI is transforming industries through automation.\",\n",
    "    \"Machine learning is a subset of AI that helps in predictions.\",\n",
    "    \"Deep learning involves neural networks for complex tasks.\",\n",
    "    \"Natural language processing helps AI understand human text.\"\n",
    "]\n",
    "user_input = \"How does AI understand text?\"\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([user_input] + responses)\n",
    "\n",
    "cosine_sim = cosine_similarity(vectors[0], vectors[1:])\n",
    "ranked_responses = sorted(zip(responses, cosine_sim[0]), key=lambda x: x[1], reverse=True)\n",
    "for response, score in ranked_responses:\n",
    "    print(f\"Response: {response} - Similarity: {score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88637b2c-ae1d-49dd-bd7b-64eaeb429bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7befa092-8817-4b3d-a1c3-d5dec285f609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b8652-8573-450e-81e7-c42b0a78e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('popular',quiet=True)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba45f8b6-5f94-4c51-8256-a7b67fca43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "df=pd.read_csv('archive (2)/Reviews.csv', nrows=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038c9d50-09a2-4cfe-b4df-764ccb5f34a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      500 non-null    int64 \n",
      " 1   ProductId               500 non-null    object\n",
      " 2   UserId                  500 non-null    object\n",
      " 3   ProfileName             500 non-null    object\n",
      " 4   HelpfulnessNumerator    500 non-null    int64 \n",
      " 5   HelpfulnessDenominator  500 non-null    int64 \n",
      " 6   Score                   500 non-null    int64 \n",
      " 7   Time                    500 non-null    int64 \n",
      " 8   Summary                 500 non-null    object\n",
      " 9   Text                    500 non-null    object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53427004-448a-4a63-baf9-1b8503184960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_2188\\1673103598.py:5: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  df['Text']=df['Text'].str.replace('[^\\w\\s]','')\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "df['Text']=df['Text'].apply(lambda x:\" \".join(x.lower() for x in x.split()))\n",
    "df['Text']=df['Text'].str.replace('[^\\w\\s]','')\n",
    "stop=stopwords.words('english')\n",
    "df['Text']=df['Text'].apply(lambda x:\" \".join(x for x in x.split() if x not in stop))\n",
    "df['Text']=df['Text'].apply(lambda x:str(TextBlob(x).correct()))\n",
    "df['Text']=df['Text'].apply(lambda x:\" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df.Text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23c2f1b9-b359-4193-8c3c-78e9e0eeee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nltk>=3.9 (from textblob)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from nltk>=3.9->textblob) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from nltk>=3.9->textblob) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/624.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 41.0/624.3 kB 495.5 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 194.6/624.3 kB 1.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 522.2/624.3 kB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 624.3/624.3 kB 3.0 MB/s eta 0:00:00\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk, textblob\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed nltk-3.8.1 textblob-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c3af0-b93d-4542-988b-ca9369266c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
